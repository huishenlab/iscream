---
title: "Getting started with iscream"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with iscream}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
#bibliography: refs.bib
link-citations: yes
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Setup

### Loading *iscream*

The number of threads can be set before or after loading the library:

```{r}
options("iscream.threads" = 8)
library(iscream)
```

### Input BED files

Running this vignette requires downloading 2GB of BED files and tabix indices
from this Zenodo record: <https://zenodo.org/records/14733834>.

```{r download_data, eval = FALSE}
snmc_zip_path <- tempfile("snmcseq2")
snmc_dir <- tempdir()
download.file(
    "https://zenodo.org/records/14733834/files/sc_beds.zip",
    destfile = snmc_zip_path
)
unzip(snmc_zip_path, exdir = snmcseq2_dir)

genes_file <- tempfile("genes")
download.file(
    "https://zenodo.org/records/14733834/files/genes.bed",
    destfile = genes_file
)
```



100 human cell WGBS data from the snmc-seq2 dataset:

```{r}
bedfiles <- list.files(
  snmc_dir,
  pattern = "*.bed.gz$",
  full.names = TRUE
)[1:100]
```
### Regions

Since *iscream* is a region-based querying tool, we need to load some regions.
Here we'll be using 5000 gene body regions as the input:

```{r}
library(data.table)
regions <- fread(
  genes_file,
  col.names = c("chr", "start", "end", "gene")
)[1:5000]
head(regions)
```

## Running iscream

### Make tabix queries

The `tabix()` function can be used to query regions from BED files much like the
*tabix* shell command. It returns the queried lines from the BED files, parsed
into columns, as a `data.table`. `tabix()` is a generic BED files query function
and is not restricted to methylation BED files. It has built-in support for
BISCUIT, Bismark, and BSBolt BED file column names, set with the `aligner`
argument, but can take other column names with the `colnames` argument.

If multiple input files are provided, they are queried in parallel. If `raw =
TRUE`, `tabix()` will return the same data as `Rsamtools::scanTabix()` does - a
named list of strings.

```{r}
system.time(tbx_query <- tabix(bedfiles, regions))
tbx_query
```

### Get summary data

To get a summary of the methylation information of the gene bodies use
`summarize_regions`, providing the gene name column as the feature column:

```{r}
system.time(summary_query <- summarize_meth_regions(
  bedfiles,
  regions,
  feature_col = "gene")
)
head(summary_query)
```

Alternatively to get just the beta column use the general `summarize_regions()`
function, specifying the columns to summarize:

```{r, eval = FALSE}
system.time(summary_query <- summarize_regions(
  bedfiles,
  regions,
  columns = 4,
  col_names = "beta",
  feature_col = "gene")
)
```

### Build matrices

The `make_bsseq_mat()` function queries and stores every CpG in the input
regions. Unlike `summarize_regions()` the output matrix dimensions are unknown
at runtime. Although usually quite fast, if the CpG count is very large and
there are few overlaps in the CpGs between files, this can take a long time.
Here, gene bodies are large and the final matrix can contain millions of CpGs.
Further, with single-cell data, chances are new CpGs are found in every file.

Preallocating the number of rows, however, can drastically reduce runtime.
Since we got 45 million CpGs from all the BED files with the tabix query above,
we can expect approximately between 5 and 10 million unique CpGs as single-cell
data has lower coverage than bulk. We already have the tabix query so we can get
the unique CpG count here and use it to preallocate the matrix, reducing the
number of matrix resizes. We'll add 100,000 extra on top of the existing count
to be safe since every avoided resize cuts off at least a couple seconds from
the runtime. Making tabix queries can be a relatively quick way to approximate
the CpG count of a dataset. If you haven't done a tabix query of the full
dataset, you can approximate how many CpGs to expect based on CpG counts in one
file and the coverage of your WGBS method.

```{r}
cpg.count <- tbx_query$start |> unique() |> length()
system.time(meth_mat <- make_bsseq_mat(
  bedfiles,
  regions,
  sparse = TRUE,
  prealloc = cpg.count + 1e5
))
str(meth_mat)
```

The output of `make_bsseq_mat()` is a named list containing matrices of coverage
values and M values and vectors of the sample names, chromosome names and
positions of the loci.

This list can be used to produce a BSseq object. However since BSseq cannot work
with sparse matrices, the two matrices would need to be converted to dense
matrices first.

```{r, eval = FALSE}
bs <- do.call(BSseq, meth_mat)
```

If you want just one column from the BED file as a matrix instead of the two
for BSseq, use `make_mat()`. For example, to get a matrix of beta values
(column 4 in the BISCUIT BED file) run


```{r, eval = FALSE}
make_mat(bedfiles, regions, col = 4, mat_name = "beta")`
```

## Session info

```{r session}
sessionInfo()
```

<!-- vim: set filetype=rmd: -->
